{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# üçõ Dapoer-AI: Agentic Chatbot for Indonesian Food Recipes using Langchain and Gemini API\n",
        "\n",
        "Dapoer-AI is an agentic chatbot built using Langchain and Gemini API to help users explore Indonesian food recipes. The chatbot can:\n",
        "- Search recipes by title.\n",
        "- Find dishes based on ingredients.\n",
        "- Suggest recipes based on cooking methods.\n",
        "- Recommend easy-to-cook dishes.\n",
        "- Retrieve recipes using FAISS vector search and RAG (Retrieval-Augmented Generation)."
      ],
      "metadata": {
        "id": "C8V7OC4y8Ptt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üîó Access the Dapoer-AI Application\n",
        "\n",
        "- Streamlit App: [Dapoer-AI](https://dapoer-ai-audreynazhira.streamlit.app)  \n",
        "- Dataset: [Indonesian_Food_Recipes.csv](https://raw.githubusercontent.com/audreeynr/dapoer-ai/refs/heads/main/data/Indonesian_Food_Recipes.csv)"
      ],
      "metadata": {
        "id": "xIvG60tA_MR1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Install Required Libraries"
      ],
      "metadata": {
        "id": "d4JMr6Fw8dHW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wIVGqbZm4Mdt",
        "outputId": "2bcbace0-cbe7-4a1b-bca7-498aa1250d85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.26)\n",
            "Requirement already satisfied: langchain-google-genai in /usr/local/lib/python3.11/dist-packages (2.0.10)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.11/dist-packages (0.3.26)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.11/dist-packages (1.11.0)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.5)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.66)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.45)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.7)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.41)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai) (1.2.0)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.1.2)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.10.0)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.0)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.25.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.172.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.38.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (5.29.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.14.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.70.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (1.33)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.6.15)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.3)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.73.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain) (3.0.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain langchain-google-genai langchain-community faiss-cpu google-generativeai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Import Libraries\n",
        "We import essential libraries for:\n",
        "- Data processing (`pandas`, `re`)\n",
        "- Vector search (`FAISS`)\n",
        "- LLM integration (`ChatGoogleGenerativeAI`, `GoogleGenerativeAIEmbeddings`)\n",
        "- Document splitting and memory for Langchain agents"
      ],
      "metadata": {
        "id": "Kvks_vhz9c3K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import random\n",
        "import google.generativeai as gemini\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.schema import Document\n",
        "from langchain.agents import Tool, initialize_agent\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "9f-DsdkK4jQu"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Configure Google Gemini API\n",
        "We retrieve the Gemini API key from Colab's `userdata` and ensure the key is available before proceeding.\n"
      ],
      "metadata": {
        "id": "OmoyjJUG9j2l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "if not GOOGLE_API_KEY:\n",
        "    print(\"Error: GEMINI API key tidak ditemukan.\")\n",
        "    exit()"
      ],
      "metadata": {
        "id": "zmzDPE1M4rHH"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Load and Clean the Dataset\n",
        "We load the Indonesian food recipes dataset and clean it by:\n",
        "- Dropping empty rows\n",
        "- Removing duplicates\n"
      ],
      "metadata": {
        "id": "VDO-k6hx9nBI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CSV_FILE_PATH = 'https://raw.githubusercontent.com/audreeynr/dapoer-ai/refs/heads/main/data/Indonesian_Food_Recipes.csv'\n",
        "df = pd.read_csv(CSV_FILE_PATH)\n",
        "df_cleaned = df.dropna(subset=['Title', 'Ingredients', 'Steps']).drop_duplicates()"
      ],
      "metadata": {
        "id": "JN4bRTqP4lNf"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Normalize Text Data\n",
        "We preprocess the text by:\n",
        "- Lowercasing all characters\n",
        "- Removing punctuation\n",
        "- Stripping unnecessary spaces"
      ],
      "metadata": {
        "id": "bSC0Aird9tPF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_text(text):\n",
        "    if isinstance(text, str):\n",
        "        text = text.lower()\n",
        "        text = re.sub(r'[^a-z0-9\\s]', '', text)\n",
        "        text = re.sub(r'\\s+', ' ', text).strip()\n",
        "        return text\n",
        "    return text\n",
        "\n",
        "df_cleaned['Title_Normalized'] = df_cleaned['Title'].apply(normalize_text)\n",
        "df_cleaned['Ingredients_Normalized'] = df_cleaned['Ingredients'].apply(normalize_text)\n",
        "df_cleaned['Steps_Normalized'] = df_cleaned['Steps'].apply(normalize_text)"
      ],
      "metadata": {
        "id": "hUuXKACD4zB8"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Format Recipe for Display\n",
        "This function converts the recipe data into a structured text format to be displayed by the chatbot."
      ],
      "metadata": {
        "id": "JZJ-KXKr9zeB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def format_recipe(row):\n",
        "    bahan_raw = re.split(r'\\n|--|,', row['Ingredients'])\n",
        "    bahan_list = [b.strip().capitalize() for b in bahan_raw if b.strip()]\n",
        "    bahan_md = \"\\n\".join([f\"- {b}\" for b in bahan_list])\n",
        "    langkah_md = row['Steps'].strip()\n",
        "    return f\"\"\"üçΩ {row['Title']}\\n\\nBahan-bahan:\\n{bahan_md}\\n\\nLangkah Memasak:\\n{langkah_md}\"\"\""
      ],
      "metadata": {
        "id": "pHt4zH1L40fn"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Create Agent Tools\n",
        "We define 4 search tools to be used by the Langchain agent:\n",
        "1. Search by title\n",
        "2. Search by ingredients\n",
        "3. Search by cooking method\n",
        "4. Recommend easy recipes"
      ],
      "metadata": {
        "id": "1PUfkYpL92F2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def search_by_title(query):\n",
        "    query_normalized = normalize_text(query)\n",
        "    match_title = df_cleaned[df_cleaned['Title_Normalized'].str.contains(query_normalized)]\n",
        "    if not match_title.empty:\n",
        "        return format_recipe(match_title.iloc[0])\n",
        "    return \"Resep tidak ditemukan berdasarkan judul.\"\n",
        "\n",
        "def search_by_ingredients(query):\n",
        "    stopwords = {\"masakan\", \"apa\", \"saja\", \"yang\", \"bisa\", \"dibuat\", \"dari\", \"menggunakan\", \"bahan\", \"resep\"}\n",
        "    prompt_lower = normalize_text(query)\n",
        "    bahan_keywords = [w for w in prompt_lower.split() if w not in stopwords and len(w) > 2]\n",
        "\n",
        "    if bahan_keywords:\n",
        "        mask = df_cleaned['Ingredients_Normalized'].apply(lambda x: all(k in x for k in bahan_keywords))\n",
        "        match_bahan = df_cleaned[mask]\n",
        "        if not match_bahan.empty:\n",
        "            hasil = match_bahan.head(5)['Title'].tolist()\n",
        "            return \"Masakan yang menggunakan bahan tersebut:\\n- \" + \"\\n- \".join(hasil)\n",
        "    return \"Tidak ditemukan masakan dengan bahan tersebut.\"\n",
        "\n",
        "def search_by_method(query):\n",
        "    prompt_lower = normalize_text(query)\n",
        "    for metode in ['goreng', 'panggang', 'rebus', 'kukus']:\n",
        "        if metode in prompt_lower:\n",
        "            cocok = df_cleaned[df_cleaned['Steps_Normalized'].str.contains(metode)]\n",
        "            if not cocok.empty:\n",
        "                hasil = cocok.head(5)['Title'].tolist()\n",
        "                return f\"Masakan yang dimasak dengan cara {metode}:\\n- \" + \"\\n- \".join(hasil)\n",
        "    return \"Tidak ditemukan metode memasak yang cocok.\"\n",
        "\n",
        "def recommend_easy_recipes(query):\n",
        "    prompt_lower = normalize_text(query)\n",
        "    if \"mudah\" in prompt_lower or \"pemula\" in prompt_lower:\n",
        "        hasil = df_cleaned[df_cleaned['Steps'].str.len() < 300].head(5)['Title'].tolist()\n",
        "        return \"Rekomendasi masakan mudah:\\n- \" + \"\\n- \".join(hasil)\n",
        "    return \"Tidak ditemukan masakan mudah yang relevan.\""
      ],
      "metadata": {
        "id": "hXxNm-mU41Ir"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Build FAISS Vectorstore\n",
        "We build a FAISS vector index from the recipe dataset to enable fast vector-based retrieval."
      ],
      "metadata": {
        "id": "hI4ltqzi-IOb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_vectorstore(api_key):\n",
        "    docs = []\n",
        "    for _, row in df_cleaned.iterrows():\n",
        "        content = f\"Title: {row['Title']}\\nIngredients: {row['Ingredients']}\\nSteps: {row['Steps']}\"\n",
        "        docs.append(Document(page_content=content))\n",
        "\n",
        "    splitter = CharacterTextSplitter(chunk_size=300, chunk_overlap=30)\n",
        "    texts = splitter.split_documents(docs)\n",
        "\n",
        "    embeddings = GoogleGenerativeAIEmbeddings(\n",
        "        model=\"models/embedding-001\",\n",
        "        google_api_key=api_key\n",
        "    )\n",
        "\n",
        "    vectorstore = FAISS.from_documents(texts, embeddings)\n",
        "    return vectorstore"
      ],
      "metadata": {
        "id": "6TnjUhPF43b7"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Create RAG Search Function\n",
        "This function uses FAISS to retrieve relevant recipes. If no result is found, it returns random recipes as a fallback."
      ],
      "metadata": {
        "id": "LB4yIluL-R_V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rag_search(api_key, query):\n",
        "    vectorstore = build_vectorstore(api_key)\n",
        "    retriever = vectorstore.as_retriever()\n",
        "    docs = retriever.get_relevant_documents(query)\n",
        "\n",
        "    if not docs:\n",
        "        fallback_samples = df_cleaned.sample(5)\n",
        "        fallback_response = \"\\n\\n\".join([\n",
        "            f\"{row['Title']}:\\nBahan: {row['Ingredients']}\\nLangkah: {row['Steps']}\"\n",
        "            for _, row in fallback_samples.iterrows()\n",
        "        ])\n",
        "        return f\"Tidak ditemukan informasi yang relevan. Berikut beberapa rekomendasi masakan acak:\\n\\n{fallback_response}\"\n",
        "\n",
        "    return \"\\n\\n\".join([doc.page_content for doc in docs[:5]])"
      ],
      "metadata": {
        "id": "RY2XhTnQ-t1Q"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10. Create Langchain Agent\n",
        "We create an agent using:\n",
        "- 5 custom tools\n",
        "- Gemini LLM (Google Generative AI)\n",
        "- Conversation memory\n",
        "- Zero-shot agent configuration"
      ],
      "metadata": {
        "id": "gGZl914k-bmB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_agent(api_key):\n",
        "    llm = ChatGoogleGenerativeAI(\n",
        "        model=\"gemini-1.5-flash\",\n",
        "        google_api_key=api_key,\n",
        "        temperature=0.7\n",
        "    )\n",
        "\n",
        "    def rag_tool_func(query):\n",
        "        return rag_search(api_key, query)\n",
        "\n",
        "    tools = [\n",
        "        Tool(name=\"SearchByTitle\", func=search_by_title, description=\"Cari resep berdasarkan judul masakan.\"),\n",
        "        Tool(name=\"SearchByIngredients\", func=search_by_ingredients, description=\"Cari masakan berdasarkan bahan.\"),\n",
        "        Tool(name=\"SearchByMethod\", func=search_by_method, description=\"Cari masakan berdasarkan metode memasak.\"),\n",
        "        Tool(name=\"RecommendEasyRecipes\", func=recommend_easy_recipes, description=\"Rekomendasi masakan yang mudah dibuat.\"),\n",
        "        Tool(name=\"RAGSearch\", func=rag_tool_func, description=\"Cari informasi masakan menggunakan FAISS dan RAG dengan fallback rekomendasi acak.\")\n",
        "    ]\n",
        "\n",
        "    memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
        "\n",
        "    agent = initialize_agent(\n",
        "        tools=tools,\n",
        "        llm=llm,\n",
        "        agent=\"zero-shot-react-description\",\n",
        "        memory=memory,\n",
        "        verbose=True\n",
        "    )\n",
        "\n",
        "    return agent"
      ],
      "metadata": {
        "id": "kMphWFpN46_e"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent = create_agent(GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "VOiMyCET7FY4"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Selamat datang di Dapoer-AI üç≥! Kamu bisa tanya seputar resep masakan Indonesia.\")\n",
        "print(\"Tanyakan resep, bahan hingga ide masakan (atau ketik 'exit' untuk keluar).\")\n",
        "\n",
        "while True:\n",
        "    user_input = input(\"\\nKamu: \")\n",
        "    if user_input.lower() in [\"exit\", \"quit\", \"keluar\"]:\n",
        "        print(\"Terima kasih sudah menggunakan Dapoer-AI! üëã\")\n",
        "        break\n",
        "\n",
        "    response = agent.invoke(user_input)\n",
        "    print(\"\\nDapoer-AI: \", response)\n",
        "    print(\"\\n\" + \"=\" * 60 + \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QdRkmWs148Bd",
        "outputId": "e9d6532d-38de-40e5-a19f-0a9c112facc3"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selamat datang di Dapoer-AI üç≥! Kamu bisa tanya seputar resep masakan Indonesia.\n",
            "Tanyakan resep, bahan hingga ide masakan (atau ketik 'exit' untuk keluar).\n",
            "\n",
            "Kamu: tahu bacem\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mQuestion: tahu bacem\n",
            "Thought: I need to find information about tahu bacem.  Since it's a specific dish name, searching by title is the most appropriate first step.\n",
            "Action: SearchByTitle\n",
            "Action Input: tahu bacem\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3müçΩ Tahu bacem sederhana\n",
            "\n",
            "Bahan-bahan:\n",
            "- 10 bh tahu\n",
            "- 5 siung bawang merah\n",
            "- 5 siung bawang putih\n",
            "- 1 sdm ketumbar\n",
            "- 1 bh kemiri\n",
            "- Daun salam\n",
            "- Daun jeruk\n",
            "- Kecap\n",
            "- Gula jawa\n",
            "- Air\n",
            "\n",
            "Langkah Memasak:\n",
            "1) Haluskan bumbu. Bawang merah, bawang putih, ketumbar, kemiri.\n",
            "2) Siapkan panci yang diisi air kira2 1,5 liter.\n",
            "3) Masukkan tahu dan bumbu halus serta daun salam dan daun jeruk.\n",
            "4) Masukkan gula jawa dan kecap. Jgn lupa tambah kan garam.\n",
            "5) Aduk, koreksi rasa dan biarkan hingga air rebusan habis.\n",
            "6) Angkat dan simpan di kulkas(klu saya) semaleman.\n",
            "7) Gorek dengan minyak panas.\n",
            "8) Warna akan semakin coklat ketika sudah digoreng.\n",
            "9) Angkat dan sajikan\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mQuestion: tahu bacem\n",
            "Thought: I need to find information about tahu bacem.  Since it's a specific dish name, searching by title is the most appropriate first step.\n",
            "Action: SearchByTitle\n",
            "Action Input: tahu bacem\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3müçΩ Tahu bacem sederhana\n",
            "\n",
            "Bahan-bahan:\n",
            "- 10 bh tahu\n",
            "- 5 siung bawang merah\n",
            "- 5 siung bawang putih\n",
            "- 1 sdm ketumbar\n",
            "- 1 bh kemiri\n",
            "- Daun salam\n",
            "- Daun jeruk\n",
            "- Kecap\n",
            "- Gula jawa\n",
            "- Air\n",
            "\n",
            "Langkah Memasak:\n",
            "1) Haluskan bumbu. Bawang merah, bawang putih, ketumbar, kemiri.\n",
            "2) Siapkan panci yang diisi air kira2 1,5 liter.\n",
            "3) Masukkan tahu dan bumbu halus serta daun salam dan daun jeruk.\n",
            "4) Masukkan gula jawa dan kecap. Jgn lupa tambah kan garam.\n",
            "5) Aduk, koreksi rasa dan biarkan hingga air rebusan habis.\n",
            "6) Angkat dan simpan di kulkas(klu saya) semaleman.\n",
            "7) Gorek dengan minyak panas.\n",
            "8) Warna akan semakin coklat ketika sudah digoreng.\n",
            "9) Angkat dan sajikan\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mThought: I have a recipe for Tahu Bacem.  I can answer the question.\n",
            "Final Answer: Tahu Bacem is a dish made with tofu, shallots, garlic, coriander, candlenut, bay leaves, kaffir lime leaves, soy sauce, palm sugar, and water.  The ingredients are simmered together until the liquid is absorbed, then the tofu is fried until brown.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "Dapoer-AI:  {'input': 'tahu bacem', 'chat_history': '', 'output': 'Tahu Bacem is a dish made with tofu, shallots, garlic, coriander, candlenut, bay leaves, kaffir lime leaves, soy sauce, palm sugar, and water.  The ingredients are simmered together until the liquid is absorbed, then the tofu is fried until brown.'}\n",
            "\n",
            "============================================================\n",
            "\n",
            "\n",
            "Kamu: exit\n",
            "Terima kasih sudah menggunakan Dapoer-AI! üëã\n"
          ]
        }
      ]
    }
  ]
}
